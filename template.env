PERSIST_DIRECTORY="db"
MODEL_TYPE=GPT4All
MODEL_PATH=
EMBEDDINGS_MODEL_NAME="all-MiniLM-L6-v2"
MODEL_N_CTX=1000
MODEL_N_BATCH=8
TARGET_SOURCE_CHUNKS=4

RABBIT_HOST=

# coda links channel
CODA_REQUEST_QUEUE="coda.request"
CODA_REPLY_QUEUE="coda.links"

# rss blog links channel
BLOG_REQUEST_QUEUE="blog.request"
BLOG_REPLY_QUEUE="blog.links"
BLOG_RSS=

# prompt communication channels
PROMPT_QUEUE="prompt.queue"
LLM_REPLY_QUEUE="llm.queue.reply"
LLM_UPDATE_QUEUE="llm.queue.update"
LLM_STATUS_QUEUE="llm.queue.status"


